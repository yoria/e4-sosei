{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AB_class_var.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOj2O5CCJzc3k3gKZZRpcQS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h30e07/E4sosei/blob/main/AB_class_var.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD-eZp4LYURB"
      },
      "source": [
        "AかつBの単語を1とする。\n",
        "<br>\n",
        "Aから見てBとどれだけ類似しているかを出力する。つまり、$w_a$と$w_b$を入れ替えると出力が変化する。\n",
        "$$\n",
        "similarityAtoB = \\dfrac{1}{|A|}(\\dfrac{|A-A\\cap{B}|}{|A-A\\cap{B}||B-A\\cap{B}|}{\\sum_{w_a\\in{(A-A\\cap{B})}}}\\;{\\sum_{w_b\\in{(B-A\\cap{B})}}}f(w_a, w_b)+\\sum_{w_a\\in{(A\\cap{B})}}1)\n",
        "\\\\A:シラバスAに現れる全単語の集合,\n",
        "\\\\B:シラバスBに現れる全単語の集合,\n",
        "\\\\f(w_a, w_b):単語w_aと単語w_bの関連度合いを-1～1の値で返す関数,\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5SXMi6dcyFI"
      },
      "source": [
        "# Google Drive マウント\n",
        "（一番最初にこれを実行してください）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_214qFvrc85d",
        "outputId": "f5d255ae-9f89-4c37-c726-e176e4a5daca"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTVr055QdOur"
      },
      "source": [
        "# シラバスクラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lpe66lMdWQi"
      },
      "source": [
        "import re\n",
        "class Syllabus:\n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "        self.subject_name = re.sub('([0-9]+)', '', path.replace('/content/drive/MyDrive/sosei/meishi/meishi_', '').replace('.txt', '')).replace('()', '').replace('（）', '')\n",
        "        self.subject_code = re.search('[0-9]{4}', path).group()\n",
        "        self.grade = re.findall('_([0-9]{1})', path)[0]\n",
        "        self.words = \"\"\n",
        "        self.words_set = {}\n",
        "        self.remained_set = {}\n",
        "\n",
        "    def set_words_set(self):\n",
        "        with open(self.path) as s:\n",
        "            self.words = s.read()\n",
        "        self.words_set = set(self.words.split())\n",
        "        return self.words_set\n",
        "    \n",
        "    def calc_and_b_set(self, another_s_words_set):\n",
        "        self.and_b_set = self.words_set & another_s_words_set\n",
        "        return self.and_b_set\n",
        "\n",
        "\n",
        "    def calc_remained_set(self, self_and_another_set):\n",
        "        self.remained_set = self.words_set - self_and_another_set\n",
        "        return self.remained_set\n",
        "\n",
        "    def get_dict():\n",
        "        output = {\n",
        "            'path': self.path,\n",
        "            'words': self.words,\n",
        "            'words_set': self.words_set,\n",
        "            'remained_set': self.remained_set,\n",
        "            'and_b_set':self.and_b_set\n",
        "        }\n",
        "        return output"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m1XwVW3fkNY"
      },
      "source": [
        "# get_all_combinations関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slmlhxTodq-f"
      },
      "source": [
        "def get_all_combinations(sa_words, sb_words):\n",
        "    all_combinations = []\n",
        "    for sa_word in sa_words:\n",
        "        for sb_word in sb_words:\n",
        "            try:\n",
        "                all_combinations.append(\n",
        "                    {\n",
        "                        'word1': sa_word,\n",
        "                        'word2': sb_word,\n",
        "                        'similarity': float(w2v_model.similarity(sa_word, sb_word))\n",
        "                    }\n",
        "                )\n",
        "            except KeyError:\n",
        "                pass\n",
        "    sorted_all_combinations = sorted(all_combinations, key=lambda x: x['similarity'], reverse=True)\n",
        "    return sorted_all_combinations"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhA-P0qFfxCT"
      },
      "source": [
        "#関連性クラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SkKOGXIf2eG"
      },
      "source": [
        "class Similarity:\n",
        "    def __init__(self, words_combinations):\n",
        "        self.words_combinations = words_combinations\n",
        "        self.similarity = 0\n",
        "        self.key_data = {}\n",
        "        self.distribution = []\n",
        "\n",
        "    def calc_similarity(self, sa_words_count, sb_words_count, sa_and_sb_count):  #重複している単語を1とする\n",
        "        for  word_combination in self.words_combinations:\n",
        "            self.similarity += word_combination['similarity']\n",
        "        self.similarity = (self.similarity / sb_words_count + sa_and_sb_count) / (sa_words_count + sa_and_sb_count)\n",
        "        return self.similarity\n",
        "    \n",
        "    def set_key_data(self, sa_subject_name, sb_subject_name):\n",
        "        self.key_data = {\n",
        "            'word_combination_sum': len(self.words_combinations),\n",
        "            'min_similarity_value': self.words_combinations[-1]['similarity'],\n",
        "            'max_similarity_value': self.words_combinations[0]['similarity'],\n",
        "            'distribution': self.show_distribution(sa_subject_name, sb_subject_name)\n",
        "        }\n",
        "        return self.key_data\n",
        "\n",
        "\n",
        "    def show_distribution(self, sa_subject_name, sb_subject_name):\n",
        "        import numpy as np\n",
        "        import pandas as pd\n",
        "        import matplotlib.pyplot as plt\n",
        "        fig = plt.figure()\n",
        "        similarity_list = [d.get('similarity') for d in self.words_combinations]\n",
        "        bins = np.arange(-1, 1, 0.1) # 等差数列\n",
        "        sr = pd.Series(similarity_list)\n",
        "        sr1 = pd.cut(sr, bins=bins)\n",
        "        vc = sr1.value_counts(sort=False)\n",
        "        y, ind, pacthes = plt.hist(sr,bins = bins.size-2, range =(-1,1))\n",
        "        print('y', y)\n",
        "        print('ind', ind)\n",
        "        plt.xlabel(\"similarity\")\n",
        "        plt.ylabel(\"number of combinations\")\n",
        "        # plt.title(f\"{sa_path.replace('/content/drive/MyDrive/sosei/meishi/meishi_', '')}, {sb_path.replace('/content/drive/MyDrive/sosei/meishi/meishi_', '')}\", fontname=\"MS Gothic\")\n",
        "        plt.show()\n",
        "        fig.savefig(f\"/content/drive/MyDrive/sosei/result_data/沖澤AB_class_varの画像/{sa_subject_name}_{sb_subject_name}.png\")\n",
        "        return self.distribution\n",
        "    \n",
        "    def get_dict(self):\n",
        "        output = {\n",
        "            'similarity': self.similarity,\n",
        "            'key_data': self.key_data,\n",
        "            'words_combinations': self.words_combinations,\n",
        "        }\n",
        "        return output"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtJQVw2-f-gg"
      },
      "source": [
        "# シラバスの全組み合わせを重複ありで返す関数\n",
        "#(A,BとB,Aが出てくる)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LSKp0UnkLHU"
      },
      "source": [
        "def get_all_syllabus_combination():\n",
        "    import glob\n",
        "    import itertools\n",
        "    output = []\n",
        "    files = glob.glob(f\"/content/drive/MyDrive/sosei/meishi/*\")\n",
        "    print(len(files))\n",
        "    for i in files:\n",
        "      for j in files:\n",
        "        output.append([i,j])\n",
        "    return output"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uTJwdufk2P_"
      },
      "source": [
        "def syllabus_similarity(sa_path, sb_path):\n",
        "    \"\"\"\n",
        "    AかつBの単語を1として計算するメイン関数。\n",
        "    入力の2つのファイルから求められたあらゆるデータは変数outputに格納される。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    sa_path : string\n",
        "        シラバスaの形態素解析済みのファイルのパス\n",
        "    sb_path : string\n",
        "        シラバスbの形態素解析済みのファイルのパス\n",
        "    \"\"\"\n",
        "    \n",
        "    sa = Syllabus(sa_path)\n",
        "    sb = Syllabus(sb_path)\n",
        "    sa.set_words_set()\n",
        "    sb.set_words_set()\n",
        "    sa.calc_and_b_set(sb.words_set)\n",
        "    sa.calc_remained_set(sa.and_b_set)\n",
        "    sb.calc_remained_set(sa.and_b_set)\n",
        "\n",
        "    # 本処理    \n",
        "    similarity = Similarity(get_all_combinations(sa.remained_set, sb.remained_set))\n",
        "    if len(sa.remained_set) != 0:   # AがBの部分集合出ないとき\n",
        "        similarity.calc_similarity(len(sa.remained_set), len(sb.remained_set),len(sa.and_b_set))\n",
        "        similarity.set_key_data(sa.subject_name, sb.subject_name)\n",
        "    else:\n",
        "        similarity.similarity = 1\n",
        "    \n",
        "    output = {\n",
        "        'subject_combination': [sa.path, sb.path],\n",
        "        'data': similarity.get_dict()\n",
        "    }\n",
        "    print('output', output)\n",
        "    return output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUrHK6UpkvNq"
      },
      "source": [
        "# メインプログラム　AかつBの単語は1とする\n",
        "（準備ができたらこれを実行してください）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgwnjDyDmkwS"
      },
      "source": [
        "from gensim.models.word2vec import Word2Vec\n",
        "from google.colab import files\n",
        "import csv\n",
        "import json\n",
        "\n",
        "def test():\n",
        "    syllabus_path = [\n",
        "        '/content/drive/MyDrive/sosei/meishi/meishi_3電気回路ⅠA(2078).txt',\n",
        "        '/content/drive/MyDrive/sosei/meishi/meishi_3電気回路ⅠB(2079).txt',\n",
        "        '/content/drive/MyDrive/sosei/meishi/meishi_2微分積分学ⅠA(0018).txt'\n",
        "    ]\n",
        "    \n",
        "    output.append(syllabus_similarity(syllabus_path[0], syllabus_path[0]))\n",
        "    output.append(syllabus_similarity(syllabus_path[0], syllabus_path[1]))\n",
        "    output.append(syllabus_similarity(syllabus_path[0], syllabus_path[2]))  \n",
        "  \n",
        "if __name__ == '__main__':\n",
        "    output = []\n",
        "    W2V_MODEL_PATH = '/content/drive/MyDrive/sosei/Pre-Trained Word2Vec Models/latest-ja-word2vec-gensim-model/word2vec.gensim.model'\n",
        "    w2v_model = Word2Vec.load(W2V_MODEL_PATH)\n",
        "    for combination in get_all_syllabus_combination():\n",
        "      output.append(syllabus_similarity(combination[0], combination[1]))\n",
        "    ### このプログラムを実行して得られた全てのデータをファイル出力 ###\n",
        "    ###with open(f\"/content/drive/MyDrive/v2.json\", 'w') as f:\n",
        "        ###json.dump(output, f, indent=2, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}