{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2nen3nen_class_var.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/h30e07/E4sosei/blob/main/2nen3nen_class_var.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwMsACFaMhEJ"
      },
      "source": [
        "# similarityの算出方法\n",
        "\n",
        "$$\n",
        "similarity = \\dfrac{1}{|A-A\\cap{B}||B-A\\cap{B}|}{\\sum_{w_a\\in{(A-A\\cap{B})}}}\\;{\\sum_{w_b\\in{(B-A\\cap{B})}}}f(w_a, w_b)\n",
        "\\\\A:シラバスAに現れる全単語の集合,\n",
        "\\\\B:シラバスBに現れる全単語の集合,\n",
        "\\\\f(w_a, w_b):単語w_aと単語w_bの関連度合いを-1～1の値で返す関数,\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YU7XERuuTF8"
      },
      "source": [
        "# Google Drive マウント\n",
        "（一番最初にこれを実行してください）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbSi52W9t5HV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee6be86f-90e5-4228-c418-3c01c8a6cf71"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX4gD54oacbg"
      },
      "source": [
        "# シラバスクラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt84kYpiaiY6"
      },
      "source": [
        "import re\n",
        "class Syllabus:\n",
        "    def __init__(self, path):\n",
        "        self.path = path\n",
        "        self.subject_name = re.sub('([0-9]+)', '', path.replace('/content/drive/MyDrive/sosei/meishi/meishi_', '').replace('.txt', '')).replace('()', '').replace('（）', '')\n",
        "        self.subject_code = re.search('[0-9]{4}', path).group()\n",
        "        self.grade = re.findall('_([0-9]{1})', path)[0]\n",
        "        self.words = \"\"\n",
        "        self.words_set = {}\n",
        "        self.remained_set = {}\n",
        "\n",
        "    def set_words_set(self):\n",
        "        with open(self.path) as s:\n",
        "            self.words = s.read()\n",
        "        self.words_set = set(self.words.split())\n",
        "        return self.words_set\n",
        "    \n",
        "    def calc_remained_set(self, another_s_words_set):\n",
        "        self.remained_set = self.words_set - (self.words_set & another_s_words_set)\n",
        "        return self.remained_set\n",
        "\n",
        "    def get_dict():\n",
        "        output = {\n",
        "            'path': self.path,\n",
        "            'words': self.words,\n",
        "            'words_set': self.words_set,\n",
        "            'remained_set': self.remained_set\n",
        "        }\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAG7VH1i20a6"
      },
      "source": [
        "# get_all_combinations関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8zC7ECd2tgj"
      },
      "source": [
        "def get_all_combinations(sa_words, sb_words):\n",
        "    all_combinations = []\n",
        "    for sa_word in sa_words:\n",
        "        for sb_word in sb_words:\n",
        "            try:\n",
        "                all_combinations.append(\n",
        "                    {\n",
        "                        'word1': sa_word,\n",
        "                        'word2': sb_word,\n",
        "                        'similarity': float(w2v_model.similarity(sa_word, sb_word))\n",
        "                    }\n",
        "                )\n",
        "            except KeyError:\n",
        "                pass\n",
        "    sorted_all_combinations = sorted(all_combinations, key=lambda x: x['similarity'], reverse=True)\n",
        "    return sorted_all_combinations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFXPC29oujEj"
      },
      "source": [
        "# 関連性クラス"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DedMAv0HupYT"
      },
      "source": [
        "class Similarity:\n",
        "    def __init__(self, words_combinations):\n",
        "        self.words_combinations = words_combinations\n",
        "        self.similarity = 0\n",
        "        self.key_data = {}\n",
        "        self.distribution = []\n",
        "\n",
        "    def calc_similarity(self, sa_words_count, sb_words_count):\n",
        "        for  word_combination in self.words_combinations:\n",
        "            self.similarity += word_combination['similarity']\n",
        "        self.similarity /= (sa_words_count * sb_words_count)\n",
        "        return self.similarity\n",
        "    \n",
        "    def set_key_data(self, sa_subject_name, sb_subject_name):\n",
        "        self.key_data = {\n",
        "            'word_combination_sum': len(self.words_combinations),\n",
        "            'min_similarity_value': self.words_combinations[-1]['similarity'],\n",
        "            'max_similarity_value': self.words_combinations[0]['similarity'],\n",
        "            'distribution': self.show_distribution(sa_subject_name, sb_subject_name)\n",
        "        }\n",
        "        return self.key_data\n",
        "\n",
        "\n",
        "    def show_distribution(self, sa_subject_name, sb_subject_name):\n",
        "        import numpy as np\n",
        "        import pandas as pd\n",
        "        import matplotlib.pyplot as plt\n",
        "        fig = plt.figure()\n",
        "        similarity_list = [d.get('similarity') for d in self.words_combinations]\n",
        "        bins = np.arange(-1, 1, 0.1) # 等差数列\n",
        "        sr = pd.Series(similarity_list)\n",
        "        sr1 = pd.cut(sr, bins=bins)\n",
        "        vc = sr1.value_counts(sort=False)\n",
        "        y, ind, pacthes = plt.hist(sr,bins = bins.size-2, range =(-1,1))\n",
        "        print('y', y)\n",
        "        print('ind', ind)\n",
        "        plt.xlabel(\"similarity\")\n",
        "        plt.ylabel(\"number of combinations\")\n",
        "        # plt.title(f\"{sa_path.replace('/content/drive/MyDrive/sosei/meishi/meishi_', '')}, {sb_path.replace('/content/drive/MyDrive/sosei/meishi/meishi_', '')}\", fontname=\"MS Gothic\")\n",
        "        plt.show()\n",
        "        fig.savefig(f\"/content/drive/MyDrive/imgs/{sa_subject_name}_{sb_subject_name}.png\")\n",
        "        return self.distribution\n",
        "    \n",
        "    def get_dict(self):\n",
        "        output = {\n",
        "            'similarity': self.similarity,\n",
        "            'key_data': self.key_data,\n",
        "            'words_combinations': self.words_combinations,\n",
        "        }\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88BPZqQxJ1Vk"
      },
      "source": [
        "# シラバスの全組み合わせを返す関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUvlaZnRJ5hg"
      },
      "source": [
        "def get_all_syllabus_combination():\n",
        "    import glob\n",
        "    import itertools\n",
        "    output = []\n",
        "    files = glob.glob(f\"/content/drive/MyDrive/sosei/meishi/*\")\n",
        "    print(len(files))\n",
        "    output = list(itertools.combinations(files, 2))\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgmDjkftdTQb"
      },
      "source": [
        "def syllabus_similarity(sa_path, sb_path):\n",
        "    \"\"\"\n",
        "    メイン関数。\n",
        "    入力の2つのファイルから求められたあらゆるデータは変数outputに格納される。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    sa_path : string\n",
        "        シラバスaの形態素解析済みのファイルのパス\n",
        "    sb_path : string\n",
        "        シラバスbの形態素解析済みのファイルのパス\n",
        "    \"\"\"\n",
        "    \n",
        "    sa = Syllabus(sa_path)\n",
        "    sb = Syllabus(sb_path)\n",
        "    sa.set_words_set()\n",
        "    sb.set_words_set()\n",
        "    sa.calc_remained_set(sb.words_set)\n",
        "    sb.calc_remained_set(sa.words_set)\n",
        "\n",
        "    # 本処理    \n",
        "    similarity = Similarity(get_all_combinations(sa.remained_set, sb.remained_set))\n",
        "    if len(sa.remained_set) != 0  and len(sb.remained_set) != 0:   # 2つが部分集合出ないとき\n",
        "        similarity.calc_similarity(len(sa.remained_set), len(sb.remained_set))\n",
        "        similarity.set_key_data(sa.subject_name, sb.subject_name)\n",
        "    else:\n",
        "        similarity.similarity = 1\n",
        "    \n",
        "    output = {\n",
        "        'subject_combination': [sa.path, sb.path],\n",
        "        'data': similarity.get_dict()\n",
        "    }\n",
        "    print('output', output)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfiLqcELZXwt"
      },
      "source": [
        "# メインプログラム　AかつBの単語を取り除く(0かける)\n",
        "（準備ができたらこれを実行してください）\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8maTfpRZCMO"
      },
      "source": [
        "from gensim.models.word2vec import Word2Vec\n",
        "from google.colab import files\n",
        "import csv\n",
        "import json\n",
        "\n",
        "def test():\n",
        "    syllabus_path = [\n",
        "        '/content/drive/MyDrive/sosei/meishi/meishi_3電気回路ⅠA(2078).txt',\n",
        "        '/content/drive/MyDrive/sosei/meishi/meishi_3電気回路ⅠB(2079).txt',\n",
        "        '/content/drive/MyDrive/sosei/meishi/meishi_2微分積分学ⅠA(0018).txt'\n",
        "    ]\n",
        "    \n",
        "    output.append(syllabus_similarity(syllabus_path[0], syllabus_path[0]))\n",
        "    output.append(syllabus_similarity(syllabus_path[0], syllabus_path[1]))\n",
        "    output.append(syllabus_similarity(syllabus_path[0], syllabus_path[2]))  \n",
        "  \n",
        "if __name__ == '__main__':\n",
        "    output = []\n",
        "    W2V_MODEL_PATH = '/content/drive/MyDrive/sosei/Pre-Trained Word2Vec Models/latest-ja-word2vec-gensim-model/word2vec.gensim.model'\n",
        "    w2v_model = Word2Vec.load(W2V_MODEL_PATH)\n",
        "    for combination in get_all_syllabus_combination():\n",
        "      output.append(syllabus_similarity(combination[0], combination[1]))\n",
        "    ### このプログラムを実行して得られた全てのデータをファイル出力 ###\n",
        "    with open(f\"/content/drive/MyDrive/v2.json\", 'w') as f:\n",
        "        json.dump(output, f, indent=2, ensure_ascii=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}